root / 123456

# 1，环境规划

## 1.1，中间件版本

| 中间件名称 | 中间件版本 | 是否集群搭建 |
| ---------- | ---------- | ------------ |
| hadoop     | 3.2.1      | 是           |
| hive       | 3.1.2      | 是           |
| hbase      | 2.3.5      | 是           |
| zookeeper  | 3.4.12     | 是           |
| mysql      | 5.7.21     | 否           |
|            | 3.0.0      | 是           |

## 1.2，端口规划

| 中间价    | 端口应用          | hadoop102 | hadoop103 | hadoop104 |
| --------- | ----------------- | --------- | --------- | --------- |
| hadoop    | hdfs交互端口      | 8020      |           |           |
|           | hdfs页面访问      | 9870      |           |           |
|           | 2nn页面访问       |           |           | 9868      |
|           | yarn页面访问      |           | 8088      |           |
|           | 历史服务器地址    | 10020     |           |           |
|           | 历史服务器WEB访问 | 19888     |           |           |
| MySQL     | 连接端口(3306)    | 3306      |           |           |
| Hive      | 集群交互端口      | 9083      |           |           |
|           | JDBC(10000)       | 10000     |           |           |
| Zookeeper | 连接端口(2181)    | 2181      | 2181      | 2181      |
|           | 通信端口(2888)    | 2888      | 2888      | 2888      |
|           | 选举端口(3888)    | 3888      | 3888      | 3888      |
| Spark     | 内部通信          | 7077      |           |           |
|           | Worker页面访问    | 8081      |           |           |
|           | Master页面访问    | 8080      |           |           |
|           | 历史服务器        | 18080     |           |           |

# 2，基础环境准备

## 2.1，基础环境搭建

### 2.1.1，VMWare安装

- 激活码：`UY758-0RXEQ-M81WP-8ZM7Z-Y3HDA`

### 2.1.2，CentOS 7 硬件安装

#### 2.1.2.1，安装软件操作系统

- 虚拟机搭建

![1615866963772](E:\gitrepository\study\note\image\环境搭建\1615866963772.png)

- 虚拟机手动分区

  ![1615875558199](E:\gitrepository\study\note\image\环境搭建\1615875558199.png)

- 虚拟机网络和主机名

  ![1615875677955](E:\gitrepository\study\note\image\环境搭建\1615875677955.png)

- 创建用户名密码，完成安装

  ```
  admin  123456
  ```

  ![1615875940665](E:\gitrepository\study\note\image\环境搭建\1615875940665.png)

- 图形化界面和命令行界面切换

  ```java
  // 查看现在界面
  systemctl get-default
  // 修改为图形化界面
  systemctl set-default graphical.target
  // 修改为命令行界面
  systemctl set-default multi-user.target
  ```

#### 2.1.2.2，配置IP地址

- `VMWare` IP设置

  ![1615878089717](E:\gitrepository\study\note\image\环境搭建\1615878089717.png)

- `Windows` IP设置，设置为同一网段

  ![1615878295939](E:\gitrepository\study\note\image\环境搭建\1615878295939.png)

- `CentOS7` 静态IP配置

  ```java
  // 修改文件
  vim /etc/sysconfig/network-scripts/ifcfg-ens33
  ```

  ```json
  TYPE="Ethernet"
  PROXY_METHOD="none"
  BROWSER_ONLY="no"
  // 修改为静态IP，
  // dhcp：动态IP
  // static：静态IP
  BOOTPROTO="static"
  DEFROUTE="yes"
  IPV4_FAILURE_FATAL="no"
  IPV6INIT="yes"
  IPV6_AUTOCONF="yes"
  IPV6_DEFROUTE="yes"
  IPV6_FAILURE_FATAL="no"
  IPV6_ADDR_GEN_MODE="stable-privacy"
  NAME="ens33"
  UUID="4335716f-5f90-4d6d-9767-247e9a225f4b"
  DEVICE="ens33"
  ONBOOT="yes"
  // 静态IP地址
  IPADDR=192.168.10.100
  // 网关
  GATEWAY=192.168.10.2
  // 域名解析器
  DNS1=192.168.10.2
  ```

#### 2.1.2.3，配置主机名称

- 修改主机名称

  ```java
  // 修改文件
  vim /etc/hostname
  ```

  ![1615881117509](E:\gitrepository\study\note\image\环境搭建\1615881117509.png)

- 修改IP映射文件

  ```java
  // 修改文件
  vim /etc/hosts
  ```

  ![1615881277520](E:\gitrepository\study\note\image\环境搭建\1615881277520.png)

### 2.1.3，虚拟机配置软件

- 安装 `epel-release`：`Extra Packages for Enterprise Linux` 是为“红帽系”的操作系统提供额外的软件包，适用于 `RHEL`、`CentOS` 和 `Scientific Linux`。相当于一个软件仓库，大多数 `rpm` 包在官方仓库中是找不到的

  ```java
  [root@Hadoop100 ~]# yum install -y epel-release
  ```

- 关闭防火墙，关闭防火墙软件自启

  ```java
  // 关闭防火墙
  systemctl stop firewalld
  // 关闭防火墙开机自启动
  systemctl disable firewalld.service
  ```

- 给指定用户添加最高权限

  ```java
  // 在该文件修改权限
  [root@Hadoop100 ~]# vim /etc/sudoers
  // 在指定用户权限不足时，通过添加 sudo 前缀，提升权限
  [pj_zhang@Hadoop100 opt]$ sudo rm -rf rh/
  ```

  ![1615887716716](E:\gitrepository\study\note\image\环境搭建\1615887716716.png)

  ![1615887895765](E:\gitrepository\study\note\image\环境搭建\1615887895765.png)

- 卸载自带的JDK

  ```java
  // 卸载命令
  rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps
  ```

  - `rpm -qa`：查询所安装的所有rpm软件包
  - `grep -i java`：忽略大小写，过滤带 `java` 字样的软件包
  - `xargs -n1`：每次只传递一个参数
  - `rpm -e --nodeps`：强制卸载软件

### 2.1.4，安装JDK和Hadoop

- 上传并解压文件包

- 配置环境变量

  ```java
  // 创建环境变量文件
  vim /etc/profile.d/bigdata_env.sh
  // 加载环境变量
  source /etc/profile
  ```

  ```sh
  # JAVA_HOME
  export JAVA_HOME=/opt/jdk1.8.0_171
  export PATH=$PATH:$JAVA_HOME/bin
  
  # HADOOP_HOME
  export HADOOP_HOME=/opt/hadoop-3.2.1
  export PATH=$PATH:$HADOOP_HOME/bin
  export PATH=$PATH:$HADOOP_HOME/sbin
  ```

- `Hadoop` 目录结构

  ![1615966686739](E:\gitrepository\study\note\image\环境搭建\1615966686739.png)

### 2.1.5，克隆虚拟机

- 直接克隆模板虚拟机 `Hadoop100`
- 克隆三个 `Hadoop` 节点 `Hadoop102`、`Hadoop103`、`Hadoop104`，作为集群节点使用
- 修改各个 `Hadoop` 节点的IP地址、主机名称

## 2.2，SSH无密码登录设置

- SSH免密登录配置

  ```sh
  # 在Hadoop102机器上生成公钥和私钥
  # 生成的公钥和私钥文件在 家文件夹下的 .ssh 隐藏文件夹下
  # id_rsa：表示私钥
  # id_ras.pub：表示公钥
  [root@hadoop102 .ssh]# ssh-keygen -t rsa
  
  # 将公钥分发给指定机器，则访问指定机器不需要密码
  # 在对端机器下，会在 家文件夹下的 .ssh 隐藏文件夹下，生成对应授权文件
  [root@hadoop102 .ssh]# ssh-copy-id hadoop103
  ```

- 生成秘钥对文件

  ![1616139849527](E:\gitrepository\study\note\image\环境搭建\1616139849527.png)

- 将公密文件发送到指定节点，则再次通过 `ssh` 访问该节点时，不在需要输入密码

  ![1616139944143](E:\gitrepository\study\note\image\环境搭建\1616139944143.png)

- 在指定节点，即 `Hadoop103` 下，会生成相关授权文件

  ![1616139986740](E:\gitrepository\study\note\image\环境搭建\1616139986740.png)

- 如果需要双向免密，则需要进行双向配置！

## 2.3，准备辅助脚本

### 2.3.1，`xsync` 文件同步脚本

* 在 `/root/bin` 目录下创建 `xsync` 文件，用于三台节点间变更文件同步

  ```sh
  #!/bin/bash
  #1. 判断参数个数
  # 如果此处没有参数, 即只执行了 xsync 命令, 没有带文件, 则不执行脚本
  if [ $# -lt 1 ]
  then
  	echo Not Enough Arguement!
  	exit;
  fi
  
  #2. 遍历集群所有机器
  for host in hadoop102 hadoop103 hadoop104
  do
  	# 输出正在处理的机器
  	echo ==================== $host ====================
  	#3. 遍历所有目录，挨个发送
  	for file in $@
  	do
  		#4. 判断文件是否存在
  		if [ -e $file ]
  			then
  				#5. 获取父目录
  				# dirname $file: 输出当前文件路径, 以指定路径形式输出(相对路径/绝对路径)
  				# cd -P file/dir: 进入真是文件, -P 主要考虑弱引用
  				# 此处是进入到文件真是目录, 通过 pwd 获取文件路径
  				pdir=$(cd -P $(dirname $file); pwd)
  				#6. 获取当前文件的名称
  				fname=$(basename $file)
  				# 通过ssh进入到当前遍历的机器, 强行创建文件
  				ssh $host "mkdir -p $pdir"
  				# 复制文件到遍历机器的相同目录下
  				rsync -av $pdir/$fname $host:$pdir
  			else
  				# 输出文件不存在
  				echo $file does not exists!
  		fi
  	done
  done
  ```

* 添加执行权限

  ```sh
  [root@hadoop102 bin]# chmod 777 xsync
  ```

### 2.4.2，`jpsall` 查看脚本

* 在 `/root/bin` 目录下添加 `jpsall` 脚本文件

  ```sh
  #!/bin/bash
  
  # 遍历三台机器
  for host in Hadoop102 Hadoop103 Hadoop104
  do
  	# 输出当前遍历机器
  	echo =============== $host ===============
  	# 打印 JPS 命令
  	ssh $host jps 
  done
  ```

* 添加权限

  ```sh
  [root@hadoop102 bin]# chmod 777 jpsall
  ```

### 2.4.3，分发辅助脚本

```sh
[root@hadoop102 ~]# xsync /root/bin/
```

# 3，`Hadoop` 集群搭建

## 3.1，集群部署规划

![1616142101427](E:\gitrepository\study\note\image\环境搭建\1616142101427.png)

## 3.2，配置集群

* 核心配置文件：`core-site.xml`

  ```xml
  <configuration>
      <!-- 指定 NameNode 的地址 -->
      <property>
          <name>fs.defaultFS</name>
          <value>hdfs://hadoop102:8020</value>
      </property>
  
      <!-- 指定 hadoop 数据的存储目录 -->
      <property>
          <name>hadoop.tmp.dir</name>
          <value>/opt/hadoop-3.2.1/data</value>
      </property>
      <!-- 配置 HDFS 网页登录使用的静态用户为 root -->
      <!-- 配置该用户可直接在 HDFS 页面上对文件目录进行操作 -->
      <property>
          <name>hadoop.http.staticuser.user</name>
          <value>root</value>
      </property>
  </configuration>
  ```

* HDFS配置文件：`hdfs-site.xml`

  ```xml
  <configuration>
  	<!-- nn web 端访问地址-->
  	<property>
  		<name>dfs.namenode.http-address</name>
  		<value>hadoop102:9870</value>
  	</property>
  	
  	<!-- 2nn web 端访问地址-->
  	<property>
  		<name>dfs.namenode.secondary.http-address</name>
  		<value>hadoop104:9868</value>
  	</property>
  </configuration>
  ```

* Yarn配置：`yarn-site.xml`

  ```xml
  <configuration>
  	<!-- 指定 MR 走 shuffle -->
  	<property>
  		<name>yarn.nodemanager.aux-services</name>
  		<value>mapreduce_shuffle</value>
  	</property>
  	
  	<!-- 指定 ResourceManager 的地址-->
  	<property>
  		<name>yarn.resourcemanager.hostname</name>
  		<value>hadoop103</value>
  	</property>
  	
  	<!-- 环境变量的继承 -->
  	<property>
  		<name>yarn.nodemanager.env-whitelist</name>
  		<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
  	</property>
      <!-- 开启日志聚集功能 -->
      <property>
          <name>yarn.log-aggregation-enable</name>
          <value>true</value>
      </property>
      <!-- 设置日志聚集服务器地址 -->
      <property> 
          <name>yarn.log.server.url</name> 
          <value>http://hadoop102:19888/jobhistory/logs</value>
      </property>
      <!-- 设置日志保留时间为 7 天 -->
      <property>
          <name>yarn.log-aggregation.retain-seconds</name>
          <value>604800</value>
      </property>
  </configuration>
  ```

* MapReduce配置：`mapred-site.xml`

  ```xml
  <configuration>
  	<!-- 指定 MapReduce 程序运行在 Yarn 上 -->
  	<property>
  		<name>mapreduce.framework.name</name>
  		<value>yarn</value>
  	</property>
      <!-- 历史服务器端地址 -->
      <property>
          <name>mapreduce.jobhistory.address</name>
          <value>hadoop102:10020</value>
      </property>
      <!-- 历史服务器 web 端地址 -->
      <property>
          <name>mapreduce.jobhistory.webapp.address</name>
          <value>hadoop102:19888</value>
      </property>
  </configuration>
  ```

* 在 `{HADOOP_HOME}/etc/hadoop` 路径下配置 `workers` 文件

  ```sh
  hadoop102
  hadoop103
  hadoop104
  ```

* `root` 账号操作时单独配置，在 `{HADOOP_HOME}/sbin` 下修改

  * 修改 `start-dfs.sh` 和 `stop-dfs.sh` 文件：在文件头加下面内容

  ```sh
  #!/usr/bin/env bash     -> # 这表示第一行
  HDFS_DATANODE_USER=root
  HADOOP_SECURE_DN_USER=hdfs
  HDFS_NAMENODE_USER=root
  HDFS_SECONDARYNAMENODE_USER=root
  ```

  - 修改 `start-yarn.sh` 和 `stop-yarn.sh` 文件：在文件头加下面内容

  ```sh
  #!/usr/bin/env bash
  YARN_RESOURCEMANAGER_USER=root
  HADOOP_SECURE_DN_USER=yarn
  YARN_NODEMANAGER_USER=root
  ```

## 3.4，启动集群

* 格式化 `NameNode`

  ```sh
  [root@Hadoop102 hadoop]# hdfs namenode -format
  ```

* 格式化完成后直接一键启动

## 3.5，Hadoop集群一键启动脚本

* 在 `/root/bin` 路径下创建文件 `myhadoop`，文件内容如下

  ```sh
  #!/bin/bash
  
  # 输入参数少于一个, 错误退出
  if [ $# -lt 1 ]
  	then
  		echo "No Args Input..."
  		exit ;
  fi
  
  # 对入参字符进行分支处理
  case $1 in
  "start")
  	# 启动脚本分支处理, 依次启动各个服务组件
  	echo " =================== 启动 hadoop 集群 ==================="
  	echo " --------------- 启动 hdfs ---------------"
  	# 在 102 启动 HDFS
  	ssh hadoop102 "/opt/hadoop-3.2.1/sbin/start-dfs.sh"
  	echo " --------------- 启动 yarn ---------------"
  	# 在 103 启动 Yarn
  	ssh hadoop103 "/opt/hadoop-3.2.1/sbin/start-yarn.sh"
  	echo " --------------- 启动 historyserver ---------------"
  	# 在 102 启动 historyServer
  	ssh hadoop102 "/opt/hadoop-3.2.1/bin/mapred --daemon start historyserver"
  ;;
  "stop")
  	# 停止脚本分支处理, 依次停止各个服务组件
  	echo " =================== 关闭 hadoop 集群 ==================="
  	echo " --------------- 关闭 historyserver ---------------"
  	# 在 102 关闭 HistoryServer
  	ssh hadoop102 "/opt/hadoop-3.2.1/bin/mapred --daemon stop historyserver"
  	echo " --------------- 关闭 yarn ---------------"
  	# 在 103 关闭 Yarn
  	ssh hadoop103 "/opt/hadoop-3.2.1/sbin/stop-yarn.sh"
  	echo " --------------- 关闭 hdfs ---------------"
  	# 在 102 关闭 HDFS
  	ssh hadoop102 "/opt/hadoop-3.2.1/sbin/stop-dfs.sh"
  ;;
  *)
  	# 其他输入均为错误处理
  	echo "Input Args Error..."
  ;;
  esac
  ```

# 4，`Hive` 集群搭建

## 4.1，集群环境环境

### 4.1.1，修改环境变量

```sh
# 修改环境变量
[root@hadoop102 hive-3.1.2]# vim /etc/profile.d/bigdata_env.sh
# 生效环境变量
[root@hadoop102 hive-3.1.2]# source /etc/profile
```

![1638612447456](E:\gitrepository\study\note\image\环境搭建\1638612447456.png)

### 4.1.2，修改配置文件

* 配置 `{HIVE_HIME}/conf/hive-env.sh` 文件

  ```sh
  HADOOP_HOME=/opt/hadoop-3.2.1
  JAVA_HOME=/opt/jdk1.8.0_171
  ```

* 配置 `{HIVE_HOME}/conf/hive-site.xml` 文件

  ```xml
  <?xml version="1.0" encoding="UTF-8" standalone="no"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
  <configuration>
    <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:mysql://hadoop102:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionUserName</name>
      <value>root</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionPassword</name>
      <value>123456</value>
    </property>
  </configuration>
  ```

* 上传 `mysql` 驱动包，到 `{HIVE_HOME}/lib` 下

  > mysql-connector-java-5.1.30.jar

* 用 `{HADOOP_HOME}/lib` 下面的 `guava-*.jar` 包替代 `{HIVE_HOME}/lib` 下的包，包版本问题会导致初始化失败

  ```sh
  # 删除 HIVE 下的包
  [root@hadoop102 hive-3.1.2]# rm -rf ./lib/guava-19.0.jar
  # 复制 HADOOP 下的包
  [root@hadoop102 hive-3.1.2]# cp /opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar /opt/hive-3.1.2/lib/
  ```

### 4.1.3，初始化 `Hive`

```sh
# 初始化 hive
[root@hadoop102 hive-3.1.2]# schematool -initSchema -dbType mysql
```

### 4.1.4，其他节点配置

* 分发 `{HIVE_HOME}` 文件夹到其他节点

* 修改从节点的配置信息，添加配置信息

  ```xml
  <property>
      <name>hive.metastore.uris</name>
      <value>thrift://hadoop102:9083</value>
  </property>
  ```

* 配置成功后，可从从节点直接连接到主节点

## 4.2，Hive集群启动

### 4.2.1，`hive` 直接启动

* 启动命令

  ```sh
  [root@hadoop102 hive-3.1.2]#  hive --service metastore
  ```

* 连接命令

  ```sh
  [root@hadoop102 hive-3.1.2]#  hive
  ```

### 4.2.2，`hiveserver2` 直接启动

* 启动命令

  ```sh
  [root@hadoop102 hive-3.1.2]# hiveserver2
  ```

* `beeline` 连接之前，先配置 `{HADOOP_HOME}/etc/hadoop/core-site.xml` 文件，让其他端可以通过 `HDFS` 代理的方式登录，配置完成后需要重启 `hadoop`

  ```xml
  <property>
      <name>hadoop.proxyuser.root.hosts</name>
      <value>*</value>
  </property>
  <property>
      <name>hadoop.proxyuser.root.groups</name>
      <value>*</value>
  </property>
  ```

* `beeline` 连接

  ```sh
  # 先启动beeline
  [root@hadoop103 bin]# beeline
  # 再在beeline中连接
  beeline> !connect jdbc:hive2://hadoop102:10000
  # 输入用户名密码即可
  ```

### 4.2.3，`hiveserver2` 后台启动

* 启动命令

  ```sh
  # nohup：后台运行
  # 1>：标准输出
  # 2>：错误输出
  # 后跟输出路径
  [root@hadoop102 hive-3.1.2]# nohup hiveserver2 1>/opt/logs/hive/hiveserver.log 2>/opt/logs/hive/hiveserver.log &
  ```

* `beeline` 连接同上

# 5，`MySQL`安装

* 解压 tar 包并重命名

  ```sh
  [root@hadoop102 app]# tar -zxvf mysql-5.7.21-linux-glibc2.12-x86_64.tar.gz -C /opt/
  [root@hadoop102 opt]# mv mysql-5.7.21-linux-glibc2.12-x86_64 mysql-5.7.21
  ```

* 在 `{MYSQL_HOME}` 下添加 `data` 文件夹，并添加用户组

  ```sh
  [root@hadoop102 mysql-5.7.21]# mkdir data
  [root@hadoop102 mysql-5.7.21]# groupadd mysql
  [root@hadoop102 mysql-5.7.21]# useradd -r -g mysql mysql
  ```

* 初始化 `mysql`

  ```sh
  ./bin/mysqld --initialize --user=mysql --basedir=/opt/mysql-5.7.21 --datadir=/opt/mysql-5.7.21/data
  ```

* 初始化完成后，会在 `/etc` 目录下生成 `my.cnf` 文件，修改该文件

  ```sh
  [mysqld]
  # 数据文件路径
  datadir=/opt/mysql-5.7.21/data
  # 主路径
  basedir=/opt/mysql-5.7.21
  # 端口
  port=3306
  # 绑定IP地址
  bind-address=0.0.0.0
  # 编码集
  character-set-server = utf8
  explicit_defaults_for_timestamp = true
  # 用户
  user=mysql
  ```

* 启动服务

  ```sh
  [root@hadoop102 mysql-5.7.21]# ./bin/mysqld_safe --user=mysql &
  ```

* 客户端连接，密码为初始化时候的密码

  ```sh
  [root@hadoop102 mysql-5.7.21]# ./bin/mysql -uroot -p
  ```

* 客户端连接后，在 `mysql` 客户端修改密码， 授权远程连接

  ```sh
  # 修改密码
  mysql> set password=password("123456");
  # 授权
  mysql> grant all privileges on *.* to'root'@'%' identified by '123456';
  # 刷新授权
  mysql> flush privileges;
  ```

* 设置服务启动，拷贝服务启动文件到 `/etc/init.d` 下面，并修改名称为 `mysql`，并填充配置信息

  ```sh
  # 拷贝文件
  [root@hadoop102 mysql-5.7.21]# cp ./support-files/mysql.server /etc/init.d/mysql
  # 添加权限
  [root@hadoop102 mysql-5.7.21]# chmod 777 /etc/init.d/mysql
  # 设置开机自启动
  [root@hadoop102 mysql-5.7.21]# chkconfig --add mysql
  ```

  ![1638609925463](E:\gitrepository\study\note\image\环境搭建\1638609925463.png)

* 服务启停操作

  ```sh
  # 启动
  [root@hadoop102 mysql-5.7.21]# systemctl start mysql
  # 查看状态
  [root@hadoop102 mysql-5.7.21]# systemctl status mysql
  # 停止
  [root@hadoop102 mysql-5.7.21]# systemctl stop mysql
  ```

# 6，`Zookeeper` 集群搭建

* 上传并解压tar包

* 在 `{ZOOKPPER_HOME}/conf` 路径下修改 `zoo_*.cfg` 文件名为 `zoo.cfg`，并配置

  ```sh
  # 修改数据文件地址
  dataDir=/opt/zookeeper-3.4.12/data
  # 添加集群节点信息
  server.1=hadoop102:2888:3888
  server.2=hadoop103:2888:3888
  server.3=hadoop104:2888:3888
  ```

* 在 `dataDir` 配置的路径下，即 `/opt/zookeeper-3.4.12/data` 路径下添加 `myid` 文件，文件内容为各自IP对应的 `server` 后的数字

  ![1638623817714](E:\gitrepository\study\note\image\环境搭建\1638623817714.png)

* 输出日志信息调整

  * 修改 `{ZOOKEEPER_HOME}/bin/zkEnv.sh`

    ![1638624226459](E:\gitrepository\study\note\image\环境搭建\1638624226459.png)

  * 修改 `{ZOOKEEPER_HOME}/bin/zkServer.sh`

    ![1638625497630](E:\gitrepository\study\note\image\环境搭建\1638625497630.png)

  * 修改 `{ZOOKEEPER_HOME}/conf/log4j.properties`，修改为按日期进行滚动

    ![1638624427183](E:\gitrepository\study\note\image\环境搭建\1638624427183.png)

    ![1638624437698](E:\gitrepository\study\note\image\环境搭建\1638624437698.png)

* 分发 `{ZOOKEEPER_HOME}` 文件到其他节点，并修改 `myid`

  ```sh
  [root@hadoop102 opt]# xsync zookeeper-3.4.12/
  ```

* 启动集群，注意从三台机器进行启动，此处做一个群起脚本文件

  ```sh
  # 添加文件
  [root@hadoop102 opt]# vim /root/bin/myzookeeper
  # 授权
  [root@hadoop102 opt]# chmod 777 /root/bin/myzookeeper
  # 启动zk
  [root@hadoop102 opt]# myzookeeper start
  # 查看zk状态
  [root@hadoop102 opt]# myzookeeper status
  # 停止zk
  [root@hadoop102 opt]# myzookeeper stop
  ```

  ```sh
  #!/bin/bash
  
  # 输入参数少于一个, 错误退出
  if [ $# -lt 1 ]
  	then
  		echo "No Args Input..."
  		exit ;
  fi
  
  # 对入参字符进行分支处理
  case $1 in
  "start")
  	for host in hadoop102 hadoop103 hadoop104
  	do
  		echo =============== 启动: $host ===============
  		ssh $host "/opt/zookeeper-3.4.12/bin/zkServer.sh start"
  	done
  ;;
  "status")
  	for host in hadoop102 hadoop103 hadoop104
  	do
  		echo =============== 状态: $host ===============
  		ssh $host "/opt/zookeeper-3.4.12/bin/zkServer.sh status"
  	done
  ;;
  "stop")
  	for host in hadoop102 hadoop103 hadoop104
  	do
  		echo =============== 停止: $host ===============
  		ssh $host "/opt/zookeeper-3.4.12/bin/zkServer.sh stop"
  	done
  ;;
  *)
  	# 其他输入均为错误处理
  	echo "Input Args Error..."
  ;;
  esac
  ```

# 7，`Spark` 集群搭建

## 7.1，`Spark-Standalone` 模式

### 7.1.1，集群规划

![1638626656916](E:\gitrepository\study\note\image\环境搭建\1638626656916.png)

### 7.1.2，配置集群文件

* 修改 `{SPARK_HOME}/conf` 目录下 `slaves.template ` 为 `slaves`，并添加 `worker` 节点

  ```sh
  hadoop102
  hadoop103
  hadoop104
  ```

* 修改 `spark-env.sh.template ` 文件名为 `spark-env.sh`，并配置，7077表示集群内部通信端口

  ```sh
  export JAVA_HOME=/opt/jdk1.8.0_171
  SPARK_MASTER_HOST=hadoop102
  SPARK_MASTER_PORT=7077
  ```

### 7.1.3，启动集群

* 配置完成后，分发文件

  ```sh
  [root@hadoop102 conf]# xsync /opt/spark-st-3.0.0/
  ```

* 启动集群

  ```sh
  [root@hadoop102 spark-st-3.0.0]# ./sbin/start-all.sh
  ```

* 集群访问

  * `worker` 节点访问：http://hadoop102:8081/
  * `master` 节点访问：http://hadoop102:8080/

### 7.1.4，集群测试

* 提交任务到集群进行计算

  ```sh
  # --class：表示程序中main方法所在的类
  # --master：Spark程序运行模式，此处表示Spark集群方式运行
  # application-jar：即jar包，没有特别参数标识，指运行类所在的jar包
  # 10：程序入口参数，用于设置应用的任务数量
  [root@hadoop102 spark-st-3.0.0]# /opt/spark-st-3.0.0/bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://hadoop102:7077 /opt/spark-st-3.0.0/examples/jars/spark-examples_2.12-3.0.0.jar 10
  ```

* 执行结果如下，找关键字即可

  ![1639313575208](E:\gitrepository\study\note\image\环境搭建\1639313575208.png)

### 7.1.5，配置历史服务器

* 修改 `spark-defaults.conf.template` 文件名为 `spark-defaults.conf`

* 配置 `spark-defaults.conf` 文件

  ```sh
  spark.eventLog.enabled           true
  # 注意此处
  # 连接是指hadoop的core-site.xml文件配置的路径
  # /directory必须在hadoop上提前存在
  spark.eventLog.dir               hdfs://hadoop102:8020/directory
  ```

* 配置 `spark-env.sh` 文件

  ```sh
  export SPARK_HISTORY_OPTS="
  # 表示页面访问端口
  -Dspark.history.ui.port=18080
  # 表示在hdfs的存储端口
  -Dspark.history.fs.logDirectory=hdfs://hadoop102:8020/directory 
  # 保存 Application 历史记录的个数，如果超过这个值，旧的应用程序信息将被删除
  -Dspark.history.retainedApplications=30"
  ```

* 分发配置文件

  ```sh
  [root@hadoop102 spark-st-3.0.0]# xsync conf/
  ```

* 重新启动集群和历史服务

  ```sh
  # 启动集群
  [root@hadoop102 spark-st-3.0.0]# ./sbin/start-all.sh
  # 启动历史服务
  [root@hadoop102 spark-st-3.0.0]# ./sbin/start-history-server.sh
  ```

* 页面验证：http://hadoop102:18080/

* 功能验证

  ```sh
  [root@hadoop102 spark-st-3.0.0]# /opt/spark-st-3.0.0/bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://hadoop102:7077 /opt/spark-st-3.0.0/examples/jars/spark-examples_2.12-3.0.0.jar 10
  ```

* 页面查看

  ![1639317492266](E:\gitrepository\study\note\image\环境搭建\1639317492266.png)

* 修改 `spark-env.sh` 文件，添加日志配置

  ```sh
  export SPARK_HISTORY_OPTS="
  -Dspark.history.ui.port=18080 
  -Dspark.history.fs.logDirectory=hdfs://linux1:8020/directory 
  -Dspark.history.retainedApplications=30"
  ```

  

## 7.2，`Zookeeper` 高可用配置

### 7.2.1，集群配置

> 通过 `Zookeeper` 进行HA高可用配置，新建一个文件夹进行配置，不要修改 `standalone` 方式

![1639317685101](E:\gitrepository\study\note\image\环境搭建\1639317685101.png)

* 复制一份集群进行zk测试

  ```sh
  # 复制文件
  [root@hadoop102 opt]# cp -r /opt/spark-st-3.0.0 /opt/spark-zk-3.0.0
  ```

* 停止 `spark` 集群，启动 `Zookeeper`

  ```sh
  [root@hadoop102 conf]# myzookeeper start
  ```

* 修改配置文件：`spark-env.sh`，此处可复制一份集群进行HA测试

  ```sh
  # 注释如下内容：
  # SPARK_MASTER_HOST=hadoop102
  # SPARK_MASTER_PORT=7077
  #Master 监控页面默认访问端口为 8080，但是可能会和 Zookeeper 冲突，所以改成 8989，也可以自
  定义，访问 UI 监控页面时请注意
  SPARK_MASTER_WEBUI_PORT=8989
  # /spark 表示在 zk 上的存储路径
  export SPARK_DAEMON_JAVA_OPTS="
  -Dspark.deploy.recoveryMode=ZOOKEEPER 
  -Dspark.deploy.zookeeper.url=hadoop102,hadoop103,hadoop104
  -Dspark.deploy.zookeeper.dir=/spark"
  ```

* 分发配置文件

  ```
  [root@hadoop102 opt]# xsync spark-zk-3.0.0/
  ```

* 启动 `spark` 集群，页面查看集群状态

  ```sh
  # 在hadoop102先启动集群
  [root@hadoop102 spark-zk-3.0.0]# ./sbin/start-all.sh
  # 在hadoop103上启动master
  [root@hadoop103 spark-zk-3.0.0]# ./sbin/start-master.sh
  ```

* 启动成功访问页面：http://hadoop102:8989/，可以看到 `hadoop102` 状态解析中，`hadoop103` 状态是备用

  ![1639319227763](E:\gitrepository\study\note\image\环境搭建\1639319227763.png)

  ![1639319304479](E:\gitrepository\study\note\image\环境搭建\1639319304479.png)

### 7.2.2，集群高可用测试

* 提交应用到高可用集群

  ```sh
  [root@hadoop102 spark-zk-3.0.0]# /opt/spark-st-3.0.0/bin/spark-submit \
  > --class org.apache.spark.examples.SparkPi \
  > --master spark://hadoop102:7077,hadoop103:7077 \
  > /opt/spark-st-3.0.0/examples/jars/spark-examples_2.12-3.0.0.jar \
  > 10
  ```

* 提交成功，宕掉 `hadoop102` 的 `master` 服务，服务会自动转移到 `hadoop103`

  ```sh
  # 查看进程
  [root@hadoop102 spark-zk-3.0.0]# jps
  15009 Master
  # 杀掉进程
  [root@hadoop102 spark-zk-3.0.0]# kill -9 15009
  ```

  ![1639319602115](E:\gitrepository\study\note\image\环境搭建\1639319602115.png)

* 继续提交刚才的执行命令，可以看到功能正常

  ```sh
  [root@hadoop102 spark-zk-3.0.0]# /opt/spark-st-3.0.0/bin/spark-submit \
  > --class org.apache.spark.examples.SparkPi \
  > --master spark://hadoop102:7077,hadoop103:7077 \
  > /opt/spark-st-3.0.0/examples/jars/spark-examples_2.12-3.0.0.jar \
  > 10
  ```

## 7.3，`Yarn` 模式

* 重新解压一份

```sh
[root@hadoop102 spark-zk-3.0.0]# tar -zxvf /opt/app/spark-3.0.0-bin-hadoop3.2.tgz -C /opt/
[root@hadoop102 opt]# mv spark-3.0.0-bin-hadoop3.2/ spark-yarn-3.0.0
```

### 7.3.1，修改配置文件

* 修改 `{HADOOP_HOME}/etc/hadoop/yarn-site.xml` 文件，并分发

  ```xml
  <!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认
  是 true -->
  <property>
   <name>yarn.nodemanager.pmem-check-enabled</name>
   <value>false</value>
  </property>
  <!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认
  是 true -->
  <property>
   <name>yarn.nodemanager.vmem-check-enabled</name>
   <value>false</value>
  </property>
  ```

* 修改 `{SPARK_HOME}/conf/spark-env.sh` 文件，并分发

  ```sh
  export JAVA_HOME=/opt/jdk1.8.0_171
  export YARN_CONF_DIR=/opt/hadoop-3.2.1/etc/hadoop
  ```

### 7.3.2，集群测试

* 重启 `hadoop` 和 `spark-yarn` 

  ```sh
  # 重启之前确保yarn的配置文件已经分发
  [root@hadoop102 spark-zk-3.0.0]# myhadoop stop
  [root@hadoop102 spark-zk-3.0.0]# myhadoop start
  # 启动spark，启动前确保分发
  [root@hadoop102 spark-yarn-3.0.0]# ./sbin/start-all.sh
  ```

  ![1639320552337](E:\gitrepository\study\note\image\环境搭建\1639320552337.png)

* 提交应用，并在 `yarn` 页面进行查看，点击 `histroy` 可进入 `hadoop` 的历史页面

  ```sh
  [root@hadoop102 conf]# /opt/spark-yarn-3.0.0/bin/spark-submit \
  > --class org.apache.spark.examples.SparkPi \
  > --master yarn \
  > --deploy-mode cluster \
  > /opt/spark-yarn-3.0.0/examples/jars/spark-examples_2.12-3.0.0.jar \
  > 10
  ```

  ![1639321077261](E:\gitrepository\study\note\image\环境搭建\1639321077261.png)

![1639321103330](E:\gitrepository\study\note\image\环境搭建\1639321103330.png)

### 7.3.3，配置历史服务器

* 修改 `spark-defaults.conf.template` 名为 `spark-defaults.conf` 并配置

  ```sh
  spark.eventLog.enabled=true
  spark.eventLog.dir=hdfs://hadoop102:8020/directory
  
  spark.yarn.historyServer.address=hadoop102:18080
  spark.history.ui.port=18080
  ```

* 修改 `spark-env.sh` 文件，并添加日志配置

  ```sh
  export SPARK_HISTORY_OPTS="
  -Dspark.history.ui.port=18080 
  -Dspark.history.fs.logDirectory=hdfs://hadoop102:8020/directory 
  -Dspark.history.retainedApplications=30"
  ```

* 重启历史服务和 `spark` 服务

  ```sh
  # 停止历史服务
  [root@hadoop102 spark-yarn-3.0.0]# ./sbin/stop-history-server.sh
  # 停止spark服务
  [root@hadoop102 spark-yarn-3.0.0]# ./sbin/stop-all.sh
  # 启动spark服务
  [root@hadoop102 spark-yarn-3.0.0]# ./sbin/start-all.sh 
  # 启动历史服务
  [root@hadoop102 spark-yarn-3.0.0]# ./sbin/start-history-server.sh
  ```

* 重新提交计算

* 点击历史进入 `spark` 历史页面

  ![1639321786075](E:\gitrepository\study\note\image\环境搭建\1639321786075.png)

## 7.4，`Windows` 环境搭建

### 7.4.1，`Hadoop` 基础环境

* <font color=red>注意，此处有 `Hadoop` 环境即可，无需一定正常启动，`Hadoop-3.2.1` 在 `Windows` 环境上还是有问题的，但是 `Spark` 启动依赖于 `Hadoop`，所以有 `Hadoop` 就行，无需保证 `Hadoop` 正常</font>
  * 解压 `hadoop-3.2.1.tar.gz` 包到指定路径，配置环境变量 `HADOOP_HOME`，并在 `PATH` 路径中添加 `bin` 和 `sbin` 路径

  ![1640507572160](E:\gitrepository\study\note\images\环境搭建\1640507572160.png)

* `hadoop-3.2.1` 包中, `bin` 目录下，缺少 `winutils.exe` 可执行文件，需要进行单独下载：https://gitcode.net/mirrors/cdarlint/winutils/-/blob/master/hadoop-3.2.1/bin/winutils.exe，下载完成后，添加到 `bin` 目录中

### 7.4.2，`Spark` 环境搭建

* 解压 `spark-3.0.0-bin-hadoop3.2.tgz` 包到指定路径，并配置环境变量

  ![1640507757103](E:\gitrepository\study\note\images\环境搭建\1640507757103.png)

* 启动 `bin` 目录下的 `spark-shell.cmd` 脚本，启动 `Spark` 本地环境

  ![1640508065349](E:\gitrepository\study\note\images\环境搭建\1640508065349.png)

* 在 `bin` 目录下创建 `word.txt` 文件，并输入部分字符，进行 `wordcount` 统计

  ```java
  hello java hello spark
  hello scala
  hello world
  hello
  ```

* 在命令框中执行 `wordcount` 命令

  ```sh
  sc.textFile("input/word.txt").flatMap(_.split(" ")).map((_, 1)).reduceByKey(_+_).collect();
  ```

  ![1640509673145](E:\gitrepository\study\note\images\环境搭建\1640509673145.png)