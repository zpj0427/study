# 1，用户行为采集平台

## 1.1，数仓概述

### 1.1.1，数仓基本概念

> 数据仓库（ Data Warehouse ）：<font color=red>是为企业制定决策，提供数据支持的</font>。可以帮助企业，改进业务流程、提高产品质量等
>
> 数据仓库的输入数据通常包括：**业务数据**、**用户行为数据**、**爬虫数据**等

* **业务数据**：就是各行业在处理事务过程中产生的数据。比如用户在电商网站中登录、下单、支付等过程中，需要和网站后台数据库进行增删改查交互，产生的数据就是业务数据。业务数据通常存储在 `MySQL`、`Oracle` 等数据库中；

* **用户行为数据**：用户在使用产品过程中，<font color=red>通过埋点收集与客户端产品交互</font>过程中产生的数据，并发往日志服务器进行保存。比如页面浏览、点击、停留、评论、点赞、收藏等。用户行为数据通常存储在日志文件中；

* **爬虫数据**：通常事通过技术手段获取其他公司网站的数据；<font color=red>爬虫爬的好、局里坐到老</font>

  ![1653983886213](E:\gitrepository\study\note\images\数仓4.0\1653983886213.png)

### 1.1.2，项目需求

> 整个用户行为采集平台由多个模块组成，具体如下：

1. <font color=red>用户行为数据采集平台</font>搭建
2. <font color=red>业务数据采集平台</font>搭建
3. <font color=red>数据仓库维度搭建</font>
4. 分析，<font color=red>设备、会员、商品、地区、活动</font>等电商核心主题，统计的报表指标近100个
5. 采用<font color=red>即席查询工具</font>，随时进行指标分析
6. 对<font color=red>集群性能进行监控</font>，发生异常需要报警
7. <font color=red>元数据管理</font>
8. <font color=red>质量监控</font>
9. <font color=red>权限管理</font>

### 1.1.3，技术选型

> 技术选型需要从数据处理的各个节点进行考虑；
>
> 技术选型的主要考虑因素：数据量大小、业务需求、行业内经验、技术成熟度、开发维护成本、总成本预算

1. 数据采集传输：<font color=red>`Flume`、`Kafka`、`Sqoop`</font>、`Logstash`、`DataX`
2. 数据存储：<font color=red>`MySQL`、`HDFS`、`HBase`</font>、`Redis`、`MongoDB`
3. 数据计算：<font color=red>`Hive`、`Tez`、`Spark`</font>、`Flink`、`Storm`
4. 数据查询：<font color=red>`Presto`、`Kylin`</font>、`Impala`、`Druid`、`ClickHouse`、`Doris`
5. 数据可视化：<font color=red>`Echarts`、`Superset`</font>、`QuickBI`、`DataV`
6. 任务调度：<font color=red>`Azkaban`、</font>`Oozie`、`DolphinScheduler`、`Airflow`
7. 集群监控：<font color=red>`Zabbix`</font>、`Prometheus`
8. 元数据管理：<font color=red>`Atlas`</font>
9. 权限管理：<font color=red>`Ranger`</font>、`Sentry`

### 1.1.4，系统数据设计

![1653983974278](E:\gitrepository\study\note\images\数仓4.0\1653983974278.png)

### 1.1.5，框架版本选型

1. 框架选型

   * `Apache`：<font color=red>运维麻烦，组件间的兼容性需要自行调研</font>（一般大厂使用）（建议使用）（本次使用）
   * `CDH`：国内使用最大的版本，不开源，目前已经开始收费（1W$/节点/年）（不建议使用）
   * `HDP`：开源，可进行二次开发，但是没有 `CDH` 稳定，国内使用较少

2. 云服务选型

   * 阿里云：`EMR`、`MaxCompute`、`DataWorks`
   * 亚马逊云：`EMR`
   * 腾讯云：`EMR`
   * 华为云：`EMR`

3. 组件版本选型

   | **框架**    | **旧版本** | **新版本** |
   | ----------- | ---------- | ---------- |
   | Hadoop      | 2.7.2      | 3.1.3      |
   | Zookeeper   | 3.4.10     | 3.5.7      |
   | MySQL       | 5.6.24     | 5.7.16     |
   | Hive        | 1.2.1      | 3.1.2      |
   | Flume       | 1.7.0      | 1.9.0      |
   | Kafka       | 0.11-0.2   | 2.4.1      |
   | Kafka Eagle | 1.3.7      | 1.4.5      |
   | Azkaban     | 2.5.0      | 3.84.4     |
   | Spark       | 2.1.1      | 3.0.0      |
   | Hbase       | 1.3.1      | 2.0.5      |
   | Phoenix     | 4.14.1     | 5.0.0      |
   | Sqoop       | 1.4.6      | 1.4.6      |
   | Presto      | 0.189      | 0.189      |
   | Kylin       | 2.5.1      | 3.0.1      |
   | Atlas       | 0.8.4      | 2.0.0      |
   | Ranger      | 2.0.0      | 2.0.0      |
   | Solr        | 5.2.1      | 7.7.0      |

### 1.1.6，集群规模

#### 1.1.6.1，集群规模计算

1. 如果每日日活100万人，每人产生100条数据，则每日会产生 <font color=red>1亿条数据</font>
2. 每条数据1KB左右，则每日数据量为：<font color=red>100GB</font>
3. 半年内不扩容、不清除，则累积数据为：<font color=red>18TB</font>
4. 数据保存三个副本：<font color=red>54TB</font>
5. 服务器预留30%左右的空间：<font color=red>77TB</font>
6. 此外，需要考虑数据分层处理、数据压缩（ES=75%，Hive=25%）、关系型数据库、消息队列等

#### 1.1.6.2，生产集群规划

* 消耗内存较大组件分开，如 `nn` 和 `rm`
* 数据传输较紧密需要放在一起，如 `kafka` 和 `zookeeper`
* 客户端尽量放在同一台机器上，方便外部访问，如 `mysql`、`hive`
* 有依赖关系的尽量放在同一台机器，如 `hive` 和 `Azkaban Executor`

| 1       | 2       | 3     | 4     | 5     | 6    | 7    | 8     | 9     | 10    |
| ------- | ------- | ----- | ----- | ----- | ---- | ---- | ----- | ----- | ----- |
| nn      | nn      | dn    | dn    | dn    | dn   | dn   | dn    | dn    | dn    |
|         |         | rm    | rm    | nm    | nm   | nm   | nm    | nm    | nm    |
|         |         | nm    | nm    |       |      |      |       |       |       |
|         |         |       |       |       |      |      | zk    | zk    | zk    |
|         |         |       |       |       |      |      | kafka | kafka | kafka |
|         |         |       |       |       |      |      | Flume | Flume | flume |
|         |         | Hbase | Hbase | Hbase |      |      |       |       |       |
| hive    | hive    |       |       |       |      |      |       |       |       |
| mysql   | mysql   |       |       |       |      |      |       |       |       |
| spark   | spark   |       |       |       |      |      |       |       |       |
| Azkaban | Azkaban |       |       |       | ES   | ES   |       |       |       |

#### 1.1.6.3，测试集群规划

| 服务名称              | 子服务           | 服务器hadoop102 | 服务器hadoop103 | 服务器hadoop104 |
| --------------------- | ---------------- | --------------- | --------------- | --------------- |
| HDFS                  | NameNode         | √               |                 |                 |
| DataNode              | √                | √               | √               |                 |
| SecondaryNameNode     |                  |                 | √               |                 |
| Yarn                  | NodeManager      | √               | √               | √               |
| Resourcemanager       |                  | √               |                 |                 |
| Zookeeper             | Zookeeper Server | √               | √               | √               |
| Flume（采集日志）     | Flume            | √               | √               |                 |
| Kafka                 | Kafka            | √               | √               | √               |
| Flume（消费Kafka）    | Flume            |                 |                 | √               |
| Hive                  | Hive             | √               |                 |                 |
| MySQL                 | MySQL            | √               |                 |                 |
| Sqoop                 | Sqoop            | √               |                 |                 |
| Presto                | Coordinator      | √               |                 |                 |
| Worker                |                  | √               | √               |                 |
| Azkaban               | AzkabanWebServer | √               |                 |                 |
| AzkabanExecutorServer | √                |                 |                 |                 |
| Spark                 |                  | √               |                 |                 |
| Kylin                 |                  | √               |                 |                 |
| HBase                 | HMaster          | √               |                 |                 |
| HRegionServer         | √                | √               | √               |                 |
| Superset              |                  | √               |                 |                 |
| Atlas                 |                  | √               |                 |                 |
| Solr                  | Jar              | √               |                 |                 |
| 服务数总计            |                  | 19              | 8               | 8               |

## 1.2，数据生成模块

### 1.2.1，目标数据

> 在业务过程中，需要搜集和分析的数据只要包括：<font color=red>页面数据、事件数据、曝光数据、启动数据、错误数据</font>

#### 1.2.1.1，页面数据

#### 1.2.1.2，事件数据

#### 1.2.1.3，曝光数据

#### 1.2.1.4，启动数据

#### 1.2.1.5，错误数据

### 1.2.2，数据埋点

#### 1.2.2.1，主流埋点方式

> 目前主流的埋点方式：包括<font color=red>代码埋点、可视化埋点、全埋点</font>

* **代码埋点**：通过调用埋点 `SDK` 函数，在需要埋点的业务逻辑位置调用接口，上报锚点数据；比如，通过对某个按钮的点击时间添加埋点函数调用，在点击该按钮时，会调用内部的 `SDK` 函数，发送数据
* **可视化埋点**：只需要研发人员集成采集 `SDK`，不需要写埋点代码，业务人员就可以通过访问分析平台的“圈选”功能，来“圈”出需要对用户行为进行捕捉的控件，并对该事件进行命名。圈选完毕后，这些配置会同步到各个用户的终端上，由采集 `SDK` 按照圈选的配置自动进行用户行为数据的采集和发送
* **全埋点**：通过在产品中嵌入 `SDK`，前端自动采集页面上的全部用户行为事件，上报埋点数据，相当于做了一个统一的埋点；然后再通过界面配置哪些数据需要在业务中进行分析

#### 1.2.2.2，埋点数据上报时机

* 在离开页面时，上传这个页面产生的所有数据（行为、事件、曝光、错误等）：
  * 优点：批处理，减少服务器交互，减轻压力；缺点：非实时
* 每个行为、事件、曝光、错误产生时，立即发送：
  * 优点：响应及时；缺点：对服务器压力较大
* 本次数据采集采用<font color=red>非实施方式</font>

#### 1.2.2.3，埋点数据日志结构

```json
{
	"common": {}, // 公共参数
	"actions": {}, // 行为数据
	"displays": {}, // 曝光数据
	"page": {}, // 页面数据
	"err": {}, // 错误数据
	"ts":  // 时间戳
}
```

### 1.2.3，服务器和JDK准备

> 参考文件 `../大数据环境搭建/环境搭建` 的 `2、基础环境准备`，进行模板机搭建和虚拟机克隆
>
> 配置模板机、克隆三台机器、准备分发脚本、配置SSH免密登陆
>
> 三台机器：Hadoop102、Hadoop103、Hadoop104
>
> JDK版本：`jdk-8u212-linux-x64.tar.gz`

#### 1.2.3.1，环境变量加载

* `Linux` 的环境变量在多个文件中配置，包括：`/etc/profile`，`/etc/prifile.d/*.sh`，`~/.bashrc`，`~/.bash_profile`

* `bash` 的运行模式可分为 `login shell` 和 `non-login shell`：`login shell` 表示通过终端，输入用户名密码连接之后；`non-login shell` 是指通过 `ssh` 等方式直接执行命令；

* `login shell` 和 `non-login shell` 的主要区别在于启动时会加载不同的配置文件：<font color=red>`login shell` 启动时会加载 `/etc/profile`、`~/.base_profile`、`~/.bashrc`；`non-login shell` 启动时只会加载 `~/.bashrc`</font>

  ![1653985504202](E:\gitrepository\study\note\images\数仓4.0\1653985504202.png)

* 在 `~/.bashrc` 文件中，会向下进行文件调用，由 `/etc/bashrc` 到 `/etc/profile.d/*.sh` 文件，所以：<font color=red>无论是 `login shell` 还是 `non-login shell` 都会加载 `/etc/profile.d/*.sh` 中的环境变量</font>

### 1.2.3，模拟数据

#### 1.2.3.1，使用日志

* 在 `./模拟数据/日志` 下上传四个文件到 `/opt/mockdata` 路径下

  ![1654075005418](E:\gitrepository\study\note\images\数仓4.0\1654075005418.png)

* 配置文件：

  * `application.yaml` ：对 `mock.data` 参数进行修改，表示业务日期
  * `path.json`：根据需求，灵活配置用户点路径和比例
  * `logback.xml`：配置日志生成路径

* 生成日志：

  * 

#### 1.2.3.2，集群日志生成脚本